<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Local AI · RedNote Rewriter (Serverless)</title>
  <style>
    :root{--bg:#f5efe6;--card:#fffaf2;--muted:#8b7e6a;--text:#3a2f24;--accent:#c86a3a;--border:#eadfce}
    body{margin:0;background:var(--bg);color:var(--text);font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica,Arial,"PingFang SC","Noto Sans CJK SC",sans-serif}
    .wrap{max-width:980px;margin:28px auto;padding:0 16px}
    h1{font-size:22px;margin:0 0 12px}
    .card{background:var(--card);border-radius:16px;padding:14px 14px 12px;border:1px solid var(--border);box-shadow:0 10px 24px rgba(120,90,60,.12)}
    textarea{width:100%;min-height:220px;background:#fffdf7;border:1px solid var(--border);border-radius:12px;color:var(--text);padding:12px;resize:vertical;font-family:inherit}
    textarea:disabled{opacity:.6}
    .row{display:flex;gap:10px;align-items:center;flex-wrap:wrap;margin-top:10px}
    button{background:var(--accent);border:0;border-radius:12px;color:white;padding:10px 14px;font-weight:600;cursor:pointer}
    button.secondary{background:#e8d6c6;color:#4b3a2c}
    button:disabled{opacity:.5;cursor:not-allowed}
    .muted{color:var(--muted);font-size:12px}
    .out{white-space:pre-wrap;line-height:1.7;background:#fffdf7;border:1px solid var(--border);border-radius:12px;padding:14px;min-height:240px;position:relative}
    .out.disabled{opacity:.6}
    .badge{background:#f1e6d9;border:1px solid var(--border);border-radius:999px;padding:4px 8px;font-size:12px}
    .status{font-size:12px;text-align:center}
    .bar{height:8px;background:#efe4d6;border-radius:999px;overflow:hidden;border:1px solid var(--border);width:100%;max-width:300px}
    .bar>div{height:100%;width:0;background:linear-gradient(90deg,#e3b18f,#c86a3a)}
    .overlay{position:absolute;inset:0;background:rgba(255,250,242,.9);border-radius:12px;display:flex;align-items:center;justify-content:center;gap:10px;flex-direction:column;z-index:10}
    .rel{position:relative}
    select{border:1px solid var(--border);border-radius:10px;padding:8px;background:#fffdf7}
    .hidden{display:none !important}
    .warning{color:#c83a3a;font-size:11px;margin-left:4px}
    .flex-spacer{flex:1}
    .checkbox-label{display:flex;align-items:center;gap:6px;font-size:13px;cursor:pointer;user-select:none}
  </style>
</head>
<body>
  <div class="wrap">
    <h1>Local AI RedNote Rewriter (Browser Inference · Serverless)</h1>
    
    <!-- Output Section (Top) -->
    <div class="card rel">
      <div class="out" id="output"></div>
      
      <!-- Overlay for Status/Loading in Output Area -->
      <div class="overlay" id="overlay">
        <div class="status" id="status">Initializing model...</div>
        <div class="bar"><div id="progress"></div></div>
        <div class="muted" id="statusDetail">First load requires download.</div>
      </div>
    </div>

    <div style="height:12px"></div>

    <!-- Input Section (Bottom) -->
    <div class="card">
      <textarea id="input" placeholder="Paste content here (Max 10000 chars)..."></textarea>
      
      <div class="row">
        <button id="run" disabled>Rewrite</button>
        
        <label class="checkbox-label">
          <input type="checkbox" id="realtimeToggle"> 
          Real-time
        </label>
        <span class="warning hidden" id="rtWarning">May increase CPU load/heat</span>

        <div class="flex-spacer"></div>

        <span class="badge" id="modelTag">Model: Not Ready</span>
        <select id="modelSelect" title="Select Model Size">
          <option value="small">Small (Faster)</option>
          <option value="large">Large (Better)</option>
        </select>
        <button class="secondary hidden" id="loadLargeBtn">Load Large Model</button>
      </div>
      
      <div class="muted" style="margin-top:10px">
        Rules: ≤3000 chars: Optimize format; >3000 chars: Summarize to ≤200 chars; Short text: Light formatting.
      </div>
    </div>
  </div>

  <script type="module">
    import { CreateMLCEngine } from 'https://esm.run/@mlc-ai/web-llm';

    const $ = (id)=>document.getElementById(id);
    const input = $('input');
    const output = $('output');
    const status = $('status');
    const statusDetail = $('statusDetail');
    const runBtn = $('run');
    const modelTag = $('modelTag');
    const progress = $('progress');
    const overlay = $('overlay');
    const modelSelect = $('modelSelect');
    const loadLargeBtn = $('loadLargeBtn');
    const realtimeToggle = $('realtimeToggle');
    const rtWarning = $('rtWarning');

    // Models
    const SMALL_MODEL = 'Qwen2-0.5B-Instruct-q4f16_1-MLC';
    const LARGE_MODEL = 'Phi-3.5-mini-instruct-q4f16_1-MLC';

    let engine;
    let currentModelId = SMALL_MODEL;
    let isSmallLoaded = false;
    let isLargeLoaded = false;
    let isGenerating = false;

    // Real-time Logic vars
    let debounceTimer = null;
    let lastRunTime = 0;

    function setStatus(t, detail=''){ 
        status.textContent = t; 
        if(detail) statusDetail.textContent = detail;
    }
    function setProgress(p){ progress.style.width = Math.max(0,Math.min(100,Math.round(p*100)))+'%' }
    
    function showOverlay(show){
        overlay.style.display = show ? 'flex' : 'none';
    }

    async function loadModel(which){
      const targetModel = which === 'large' ? LARGE_MODEL : SMALL_MODEL;
      
      // Update UI state
      showOverlay(true);
      runBtn.disabled = true;
      setStatus(`Loading ${which} model...`, 'Please wait...');
      setProgress(0);

      try{
        // If switching engines, we might need to reload or just use the same engine instance if it supports hot swap (WebLLM usually requires re-init for different weights if they are different architectures, or just CreateMLCEngine again).
        // CreateMLCEngine creates a new engine.
        engine = await CreateMLCEngine(targetModel,{
          initProgressCallback:(p)=>{
            setStatus(`Loading... ${Math.round(p.progress*100)}%`, p.text||'');
            setProgress(p.progress);
          }
        });

        currentModelId = targetModel;
        if(which === 'small') isSmallLoaded = true;
        if(which === 'large') isLargeLoaded = true;

        modelTag.textContent = `Model: ${which === 'large' ? 'Large' : 'Small'}`;
        showOverlay(false);
        runBtn.disabled = false;
        
        // Update button visibility
        updateControls();
        
      }catch(e){
        console.error(e);
        setStatus('Model Load Failed', e.message);
      }
    }

    function updateControls(){
        const selected = modelSelect.value;
        
        // Logic:
        // Small: Auto-load (fast).
        // Large: Always require manual trigger (user request).
        
        if(selected === 'large' && currentModelId !== LARGE_MODEL){
            loadLargeBtn.classList.remove('hidden');
            loadLargeBtn.textContent = isLargeLoaded ? "Switch to Large Model" : "Load Large Model (Download)";
            runBtn.disabled = true;
            modelTag.textContent = isLargeLoaded ? "Model: Paused" : "Model: Not Loaded";
        } else {
            loadLargeBtn.classList.add('hidden');
            
            // If we are on small but current is not small (and not loading), we should have auto-switched.
            // But if we are on Large and current IS Large, we are ready.
            if(selected === 'large'){
                runBtn.disabled = false;
                modelTag.textContent = "Model: Large";
            } else {
                // Selected Small
                // If current is not small, we are switching or loading.
                if(currentModelId === SMALL_MODEL){
                    runBtn.disabled = false;
                    modelTag.textContent = "Model: Small";
                } else {
                     // Still loading small?
                     runBtn.disabled = true;
                }
            }
        }
    }

    modelSelect.addEventListener('change', async () => {
        const val = modelSelect.value;
        if(val === 'large'){
            // Always manual trigger for Large
            updateControls(); 
        } else {
            // Small model: Auto switch
            if(currentModelId !== SMALL_MODEL){
                await loadModel('small');
            }
            updateControls();
        }
    });

    loadLargeBtn.addEventListener('click', () => {
        loadModel('large');
    });

    // Real-time Logic
    realtimeToggle.addEventListener('change', () => {
        const on = realtimeToggle.checked;
        rtWarning.classList.toggle('hidden', !on);
        if(!on){
            clearTimeout(debounceTimer);
        }
    });

    input.addEventListener('input', () => {
        if(!realtimeToggle.checked) return;
        
        const now = Date.now();
        clearTimeout(debounceTimer);

        // Throttle check: If it has been > 10s since last run
        if(lastRunTime > 0 && (now - lastRunTime > 10000)){
             run();
             // Debounce timer is cleared, run happens.
        } else {
             // Debounce 3s
             debounceTimer = setTimeout(run, 3000);
        }
    });

    function buildPrompt(userText){
      const len = userText.length;
      const tooLong = len>3000;
      const tooShort = len<40;

      const base = `You are a RedNote content editor. Task: "Format optimization or summary". Do not expand, fabricate, or add new info. Output in the same language as input. Layout: Subtitles ([] or #), short sentences, bullets (• or -), moderate emojis (max 1 per section).`;

      if(tooShort){
        return `${base}\nExtra Rule: Text is very short. Only light formatting. Do not expand. Keep within one short paragraph (≤60 words). Optional: 1 subtitle and 1-2 bullets.\n\nOriginal Text:\n${userText}`;
      }
      if(tooLong){
        return `${base}\nExtra Rule: Text is long. Understand key points first, then generate a summary ≤200 words. Keep clear paragraphing and bullets. Retain actionable conclusions. Strict limit: 200 words.\n\nOriginal Text:\n${userText}`;
      }
      return `${base}\nExtra Rule: Retain info and logic. Rewrite into clearer short sentences. 2-4 sections, 2-4 lines per section. Add a key point list.\n\nOriginal Text:\n${userText}`;
    }

    async function run(){
      if(isGenerating) return; // Prevent overlapping runs
      const text = input.value.trim();
      if(!text) return;
      if(text.length>10000){ alert('Text exceeds 10000 chars'); return; }
      
      isGenerating = true;
      runBtn.disabled=true; 
      
      // If we are in realtime mode, we don't want to clear the whole output if we can avoid it, but LLM generation usually rewrites.
      // Let's clear for now.
      output.textContent=''; 
      
      // We don't want to show the full overlay (blocking) for generation if we want "Non-blocking"?
      // User said: "Load model... don't block input". 
      // For "Generation", user didn't specify. Usually generation blocks input or just runs.
      // If real-time, we definitely shouldn't block input.
      // So let's NOT show the full overlay for generation. Just a status text?
      // Or maybe a small spinner in the output area?
      // The current overlay implementation covers the output area. That is fine. 
      // But we shouldn't block *input*. My HTML structure separates them. 
      // So showing overlay in output area is correct and doesn't block input.
      
      // However, for Real-time, flashing the overlay might be annoying.
      // Let's use a subtler indicator for generation if possible, or just the overlay with "Generating..."
      
      showOverlay(true);
      setStatus('Generating...');
      setProgress(1); // Indeterminate or full? Just hide bar?
      progress.parentElement.style.display = 'none'; // Hide progress bar during generation

      lastRunTime = Date.now();

      const messages=[
        {role:'system',content:'You are a high-quality social media content editor.'},
        {role:'user',content:buildPrompt(text)}
      ];
      try{
        const stream=await engine.chat.completions.create({messages,temperature:0.4,stream:true,max_tokens:600});
        
        // Once stream starts, hide overlay so we can see text appearing?
        // Or keep overlay until done? Standard UI shows text streaming.
        // So we MUST hide overlay as soon as we get the first chunk or immediately.
        showOverlay(false);
        
        for await(const chunk of stream){
          const token=chunk.choices?.[0]?.delta?.content||'';
          output.textContent+=token;
        }
        // Success
      }catch(e){ 
        console.error(e); 
        showOverlay(true);
        setStatus('Generation Failed', e.message);
        // Auto hide after error?
        setTimeout(()=>showOverlay(false), 3000);
      }finally{ 
        isGenerating = false;
        runBtn.disabled=false; 
        progress.parentElement.style.display = 'block'; // Reset
        if(output.textContent.length === 0 && !overlay.style.display === 'none'){
            // If empty and no error shown, maybe show placeholder?
        }
        // If realtime, we might trigger again.
        updateControls(); // Ensure button states are correct
      }
    }

    runBtn.addEventListener('click',run);

    // Auto load small model on enter
    loadModel('small');
  </script>
</body>
</html>
